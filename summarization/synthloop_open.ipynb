{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import llama_cpp\n",
    "from tqdm import tqdm \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import pickle\n",
    "from synth import CrossEntropyDifferential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating phi to generate suggestions\n",
    "master = llama_cpp.Llama(\n",
    "      model_path=\"models/Phi-3.5-mini-instruct.Q8_0.gguf\",\n",
    "      n_gpu_layers=-1, \n",
    "      verbose=False,\n",
    "      logits_all=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt2 to evaluate cross-entropy and train\n",
    "device = torch.device(\"cuda\")\n",
    "model_name = \"gpt2\"\n",
    "slave = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "slave.config.pad_token_id = slave.config.eos_token_id\n",
    "cross_entropy_differential = CrossEntropyDifferential(slave, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Y_slave(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        seed=\"\\n\",\n",
    "        how_many=1,\n",
    "        max_new_tokens=16,\n",
    "        temperature=1.2\n",
    "    ):\n",
    "    input = tokenizer(seed, return_tensors='pt', padding=True).to(device)\n",
    "    output = model.generate(\n",
    "            **input,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            num_return_sequences=how_many,\n",
    "            do_sample=True, # uncomment to enable fancy sampling of the output distribution\n",
    "            no_repeat_ngram_size=2,\n",
    "            pad_token_id=model.config.eos_token_id\n",
    "        )\n",
    "    return tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "def generate_Y_master(\n",
    "        model, \n",
    "        seed=\"\\n\",\n",
    "        max_new_tokens=16,\n",
    "        temperature=1.2\n",
    "    ):\n",
    "    return model(\n",
    "                seed,\n",
    "                max_tokens = max_new_tokens,\n",
    "                temperature=temperature\n",
    "            )[\"choices\"][0][\"text\"]\n",
    "\n",
    "def generate_X(Y, max_tokens=30):\n",
    "    S = \"Write a TL;DR: of the following text in exactly 5 words. No more, no less. Separate words with spaces. End with a . after writing it.\"\n",
    "    prompt = f\"\"\"<|system|>{S}<|end>\n",
    "    <|user|>{Y}<|end|>\n",
    "    <|assistant|>\"\"\"\n",
    "    return master(prompt, temperature=4, stop=[\".\"], max_tokens=max_tokens)[\"choices\"][0][\"text\"]\n",
    "\n",
    "def ced(Y,X):\n",
    "    return cross_entropy_differential(X, Y, diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      ": The United States is sending some $80 billion per year to Iraq. As long as there are sanctions, what can we do with these money when the regime's economy continues unabated and the economy is at the lowest point?\n",
      "\n",
      "(2)(A) This bill contains the following provisions:\n",
      "​(1) Nothing written nor approved by the President or any other elected or appointed director of the United Nations, or other such unelected person in the executive branch of government acting for the purposes specified by these two provisions shall be adopted by Congress so soon as is practicable that it is likely that future appropriations are not being appropriated prior to the date\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "Bathrooms open on the first Wednesday on weekdays 8-9 (1pm). At other bars one of every two Saturdays or Sundays the weekend and during the day there will be a \"special lunch break.\"\n",
      "\n",
      "There is always a line for one hour straight between the following two days. However, during rush hours and after dark (between 1:00 PM and 4:30 PM) every customer in the establishment receives a free pint while supplies last. Special-time orders are sold after 5pm.\n",
      ".7. Sunday. A small number of the bar closes at 7:45 p.m. as a small line to meet\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "\n",
      "In July of 2015, when Uber became the dominant player online within the Uber network, its popularity surged by 12 points every day. It is now the only popular app with over 100 million active users outside China (along with Paying for it on Apple's App Store). Meanwhile, Uber is seeing their traffic double every 2 days, with 20-30 million users every month. But Uber also wants all content to remain available to all users. The company and Google Inc. have argued, unsuccessfully, for years that content is \"content on a free network,\" but the fact is online content \"is an asset\", writes Simon Macfarlane, a\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "\n",
      "* Note that some of these settings are no longer visible in Firefox 9's default profile settings.\n",
      ", a default Firefox update. Update in place\n",
      "(or a configuration file):\n",
      "/etc/profile. Add to profile\n",
      "To add new profile, call. Remove default settings and Firefox will remove the changes that were shown above. The process will take approximately 10-30 minutes depending upon what settings the user is now switching to:\n",
      "Step 3 - Reset preferences To delete the defaults and keep the ones who are using those settings\n",
      "Create /etc\\profile\\config.json. Set new defaults for the Firefox add-ons menu or settings\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "The U.S. Navy is moving forward with its plans to build a shipyard based in a hangar in Singapore that it hopes will become the headquarters of Naval Systems Command (which currently handles ships for Japan) while it begins constructing new naval facilities, said a Navy source. Although Washington already plans for two additional naval sites in Taiwan in the next decade, this source said the base is less likely to be built until now. One potential source is the \"Hickory\" shipyards, located on the west coast of Singapore, rather than elsewhere in Asia.\n",
      "\n",
      "China considers South Korea it also has a presence on U'Joon Island.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    Y = generate_Y_slave(slave, tokenizer, max_new_tokens=130, temperature=1.2, how_many=1)\n",
    "    for y in Y: \n",
    "        print(f\"\\n\\nNew phrase ------------------\\n {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "A:\n",
      "\n",
      "For every word in the file (each line is considered a \"word\") we read the first letter and put it into a map of the letter-to-occurrence count.\n",
      "Map<Character, Integer> frequencyMap = new HashMap<Character, Integer>();\n",
      "for (String word : lines) {\n",
      "   for (char c : word.toCharArray())\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "\\item \\textbf{Ratio}\n",
      "\n",
      "Ratio refers to the relationship between two quantities, showing how many times one quantity is contained within the other. For example, if we have 10 apples and 5 oranges, the ratio of apples to oranges would be 2:1. \n",
      "\n",
      "\\begin{itemize}\n",
      "    \\item The concept of\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "  **Question 1:** What was the relationship between John, Mary, and Sarah based on the text provided? \n",
      "\n",
      "\n",
      "\n",
      "  **Answer 1:** The text does not provide specific information regarding the relationship between John, Mary, and Sarah. \n",
      "\n",
      "\n",
      "\n",
      " **Question 2:** Did John and Mary share a common interest in gardening? \n",
      "\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      "   ROW_NUMBER() OVER (ORDER BY i.id) as row\n",
      "FROM\n",
      "  items i\n",
      "JOIN\n",
      "  item_variants iv ON i.id = iv.item_id\n",
      "ORDER BY\n",
      "  row\n",
      ";\n",
      "\n",
      "\n",
      "CREATE TABLE item_variant_product_price(\n",
      "  id INTEGER PRIMARY KEY,\n",
      "  item_id INTE\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "from keras.models import Sequential\n",
      "from keras.layers import Lambda\n",
      "\n",
      "# Define the model architecture\n",
      "model = Sequential()\n",
      "model.add(Lambda(lambda x: x - 127.5, input_shape=(256,256,3)))\n",
      "model.summary()\n",
      "\n",
      "\n",
      "# +\n",
      "# load weights\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "\n",
      "(3). Content: A chlorine ion is formed when a chlorine atom gains one electron. This electron results in the formation of a chloride ion with a -1 charge. Question: What charge does a chloride ion have after gaining an electron?\n",
      "A chloride ion has a -1 charge after gaining one electron.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "  $144.625\n",
      "\n",
      "\n",
      "If the number of pages in the document were 180 instead of 120, how much would it cost for all copies printed at 80 copies per session, assuming the same rate of $0.25 per page and 15-minute sessions as before?\n",
      "\n",
      "To solve this problem,\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " #include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "#include <string.h>\n",
      "#include \"string.h\"\n",
      "\n",
      "void readInputFile(int* lines, int* wordsPerLine, const char* fileName)\n",
      "{\n",
      "    FILE* file;\n",
      "    file = fopen(fileName, \"r\");\n",
      "\n",
      "    int numberOf\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "* The following data sets were used:\n",
      "\n",
      "**Data 1:**\n",
      "\n",
      "|X|y|\n",
      "|--|--|\n",
      "|1 | 3 |\n",
      "|2 |5 |\n",
      "|3 |7 |\n",
      "|4 |9 |\n",
      "|5 |11|\n",
      "\n",
      "**Data 2:**\n",
      "\n",
      "|X|y|\n",
      "|--\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      "     CASE WHEN DATEDIFF(day, [date_from],[date_to]) BETWEEN 0 AND 6\n",
      "    THEN '1-6 days'\n",
      "    ELSE '>7 days'\n",
      "    END\n",
      "    AS [Date Range],\n",
      "    [Status]\n",
      "FROM\n",
      "    @TempTable\n",
      "ORDER BY\n",
      "    DateRange\n",
      ";\n",
      "\n",
      "--\n",
      "--\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "from flask_login import login_user, logout_user, login_required, current_user\n",
      "from flask_sqlalchemy import SQLAlchemy\n",
      "from werkzeug.security import generate_password_hash\n",
      "\n",
      "\n",
      "class User(db.Model):\n",
      "    id = db.Column(db.Integer, primary_key=True)\n",
      "    username = db\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      "   [name] => [name] \n",
      "  [email] => [email] \n",
      "  [url] => [url] \n",
      "  [status] => [status] \n",
      "  [timestamp] => 2023-06-05 10:18:20\n",
      ")\n",
      "\n",
      "[2] => Array\n",
      "  (\n",
      "  [\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "\\begin{equation*}\n",
      "\\nabla \\times \\vec{v} = \\nabla \\cdot (\\vec{v} \\times \\vec{E})\n",
      "\\end{equation*}\n",
      "\n",
      "\n",
      "I've tried solving the equation in the first step using the Levi-Civita tensor but I've had no luck. The equation doesn't even make sense to me\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " #' @param \n",
      "#' \\describe{\n",
      "#'   <dt>name <code>character</code>\n",
      "#'   <dt>value <code>character</code>\n",
      "#'   <dt>value_count <code>integer</code>\n",
      "#' }\n",
      "#' @export\n",
      "\n",
      "get_value_count_for <- function(\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "Here are two examples of how you might utilize the above document:\n",
      "\n",
      "### Example 1: Utilization in a Workplace Training Module\n",
      "\n",
      "Imagine you're tasked with developing a training module for a financial firm that educates their staff about the risks of phishing attempts. Drawing from the provided document, the module can be structured as follows:\n",
      "\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "## Introduction to Inheritance in TypeScript\n",
      "\n",
      "Inheritance is a key concept in object-oriented programming (OOP), whereby a class can inherit properties and behavior from another class. In TypeScript, we can implement inheritance using the `extends` keyword, which allows a child class to inherit from a parent class.\n",
      "\n",
      "```typescript\n",
      "class Animal {\n",
      "\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "### query\n",
      "Q: Which sentence has the correct adjective order: a \" enormous Filipino leather computer \" b \" leather enormous Filipino computer \"\n",
      "A: a \" enormous Filipino leather computer \"\n",
      "\n",
      "A: The correct sentence is 'a enormous Filipino leather computer'. \n",
      "\n",
      "In English, adjectives generally follow a specific\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      "   'id': 3,\n",
      "  'name': 'Dreamer'\n",
      "},\n",
      "{\n",
      "  'id': 4,\n",
      "  'name': 'Careful'\n",
      "}\n",
      "\n",
      "\n",
      "function add(element) {\n",
      "  var obj = {\n",
      "    'id': element.id,\n",
      "    'name': element.name\n",
      "  }\n",
      "\n",
      "  let\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "def total_digits(num):\n",
      "    return sum(int(i) for i in str(num))\n",
      "\n",
      "total_digits(123) # 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "New phrase ------------------\n",
      " \n",
      "  # 获取筛选文件\n",
      "  local -r selectedFiles=`find \"$dir\" -type f -print`\n",
      "\n",
      "  for filePath in ${selectedFiles[@]}; do\n",
      "\n",
      "    if [[ ${filePath} == \"$dir\"* ]]; then\n",
      "      continue # 文件为文件夹不再进行筛\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    Y = generate_Y_master(master, max_new_tokens=80, temperature=1.2)\n",
    "    print(f\"\\n\\nNew phrase ------------------\\n {Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Given the type of spontaneous generation of GPT2 and Phi, I'd go with GPT2. Phi generates Q: A: type of spontaneous output or even code. Probably this reflects the kind of data is has been trained on, so I'll just go with GPT2. \n",
    "\n",
    "We'll use GPT2 to generate random Ys, then we'll Phi to generate Xs. Then we will use this dataset to train a new version of GPT2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = generate_Y_slave(slave, tokenizer, max_new_tokens=240, temperature=1.2)\n",
    "X = generate_X(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:31<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: (' Custom cards $25 Amazon RCT 3 years, RCRL, deck', tensor(-0.1230, device='cuda:3'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Y: {Y[0]}\\n\")\n",
    "# print(f\"X: {X}\")\n",
    "best = (\"\",0)\n",
    "for _ in tqdm(range(1000)):\n",
    "    X = generate_X(Y[0], max_tokens=16)\n",
    "    rank = ced(Y[0], X)\n",
    "    if rank < best[1]:\n",
    "        best = (X, rank)\n",
    "print(f\"Best: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: (' Buy custom cards online for $25, missing Amazon deck info', tensor(-0.0992, device='cuda:3'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# print(f\"Y: {Y[0]}\\n\")\n",
    "# print(f\"X: {X}\")\n",
    "best = (\"\",0)\n",
    "for _ in tqdm(range(100)):\n",
    "    X = generate_X(Y[0], max_tokens=16)\n",
    "    rank = ced(Y[0], X)\n",
    "    if rank < best[1]:\n",
    "        best = (X, rank)\n",
    "print(f\"Best: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen = 200\n",
    "gamma = -0.75\n",
    "new_suggestions = []\n",
    "\n",
    "barra = tqdm(total=n_gen)\n",
    "\n",
    "while len(new_suggestions) < n_gen:\n",
    "    Y = generate_Y_slave(slave, tokenizer, max_new_tokens=240, temperature=1.2)\n",
    "    X = generate_X(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_gen = 5000\n",
    "gamma = -0.4\n",
    "new_suggestions = []\n",
    "\n",
    "barra = tqdm(total=n_gen)\n",
    "\n",
    "while len(new_suggestions) < n_gen:    \n",
    "    suggestion = generate_suggestion()\n",
    "    rank = rank_suggestion(suggestion)\n",
    "    if rank < gamma:\n",
    "        barra.update(1)\n",
    "        new_suggestions.append({f\"{Y}::TLDR::{suggestion}\":rank.item()})\n",
    "\n",
    "barra.close()\n",
    "phi.close()\n",
    "\n",
    "with open('pizza_synthdataset.pkl', 'wb') as f:\n",
    "    pickle.dump(new_suggestions, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
